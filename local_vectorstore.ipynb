{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.human import HumanInputLLM\n",
    "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Agent\n",
    "import langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Perry, what's up?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi Perry, my name is AI. I'm doing well, thank you for asking. How can I help you today?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define memory \n",
    "\n",
    "llm = OpenAI(temperature=0) # Can be any valid LLM\n",
    "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Relevant pieces of previous conversation:\n",
    "{history}\n",
    "\n",
    "(You do not need to use these pieces of information if not relevant)\n",
    "\n",
    "Current conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm, \n",
    "    prompt=PROMPT,\n",
    "    # We set a very low max_token_limit for the purposes of testing.\n",
    "    memory=ConversationBufferMemory(),\n",
    "    verbose=True\n",
    ")\n",
    "conversation_with_summary.predict(input=\"Hi, my name is Perry, what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a chatbot having a conversation with a human.\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(), \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
      "\n",
      "\n",
      "Human: Hi there my friend\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hi there! How can I help you today?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"Hi there my friend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
      "\n",
      "Human: Hi there my friend\n",
      "AI:  Hi there! How can I help you today?\n",
      "Human: Not too bad - Summarize Feyman's lectures\n",
      "AI:  Richard Feynman gave a series of lectures at the University of California, Berkeley in 1962. The lectures provide a comprehensive overview of physics, covering topics such as Newtonian mechanics, quantum mechanics, thermodynamics, electromagnetism, and more. The lectures remain popular to this day because of their clarity and insight.\n",
      "Human: Not too bad - Summarize Balaji's thesis on startups\n",
      "AI:  Balaji's thesis on startups focuses on understanding the unique characteristics of startups, such as their resource constraints, limited funding, and need for fast decision-making in order to succeed. Specifically, Balaji suggests that startups should focus on customer development, lean methodology, and developing a unique value proposition in order to create a sustainable business.\n",
      "Human: Not too bad - Summarize Balaji's thesis on the Idea Maze\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Balaji's thesis on the Idea Maze explores how entrepreneurs can navigate the process of coming up with a business idea. Specifically, Balaji suggests that entrepreneurs should think beyond the obvious, use creative problem-solving techniques, and look to the past for inspiration in order to come up with a winning business idea.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"Not too bad - Summarize Balaji's thesis on the Idea Maze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Metro_zori_sm_month.csv') as f:\n",
    "    state_of_the_union = f.read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(state_of_the_union)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (0.3.23)\n",
      "Requirement already satisfied: pandas>=1.3 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (2.0.1)\n",
      "Requirement already satisfied: requests>=2.28 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (2.29.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (1.10.7)\n",
      "Requirement already satisfied: hnswlib>=0.7 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (0.7.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (0.5.24)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.2 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (2.2.2)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (0.8.0)\n",
      "Requirement already satisfied: fastapi>=0.85.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (0.95.2)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (1.22.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from chromadb) (4.5.0)\n",
      "Requirement already satisfied: certifi in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.5.7)\n",
      "Requirement already satisfied: urllib3>=1.26 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
      "Requirement already satisfied: pytz in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3)\n",
      "Requirement already satisfied: zstandard in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
      "Requirement already satisfied: lz4 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from fastapi>=0.85.1->chromadb) (0.27.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from pandas>=1.3->chromadb) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.29.2)\n",
      "Requirement already satisfied: tqdm in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.14.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.2)\n",
      "Requirement already satisfied: scipy in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.10.1)\n",
      "Requirement already satisfied: nltk in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.14.1)\n",
      "Requirement already satisfied: click>=7.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: filelock in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (2023.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (21.3)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.6.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (0.13.3)\n",
      "Requirement already satisfied: joblib in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (9.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{\"source\": i} for i in range(len(texts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (23.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: mosaicml[nlp,streaming]==0.10.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (0.10.1)\n",
      "Requirement already satisfied: pyyaml<7,>=6.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (6.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.62.3 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (4.65.0)\n",
      "Requirement already satisfied: torchmetrics<0.8,>=0.7.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (0.7.3)\n",
      "Requirement already satisfied: torch-optimizer<0.4,>=0.3.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (0.3.0)\n",
      "Requirement already satisfied: torchvision>=0.10.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (0.14.1)\n",
      "Requirement already satisfied: torch<2,>=1.10 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (1.13.1)\n",
      "Requirement already satisfied: yahp<0.2,>=0.1.3 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (0.1.3)\n",
      "Requirement already satisfied: requests<3,>=2.26.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (2.29.0)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.21.5 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (1.22.4)\n",
      "Requirement already satisfied: psutil<6,>=5.8.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (5.9.5)\n",
      "Requirement already satisfied: coolname<2,>=1.1.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (1.1.0)\n",
      "Requirement already satisfied: tabulate==0.8.10 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (0.8.10)\n",
      "Requirement already satisfied: py-cpuinfo<9,>=8.0.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (8.0.0)\n",
      "Requirement already satisfied: packaging<22,>=21.3.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (21.3)\n",
      "Requirement already satisfied: importlib-metadata<5,>=4.11.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (4.13.0)\n",
      "Requirement already satisfied: mosaicml-streaming in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (0.4.1)\n",
      "Requirement already satisfied: boto3<2,>=1.21.45 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (1.26.136)\n",
      "Requirement already satisfied: paramiko<3,>=2.11.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (2.12.0)\n",
      "Requirement already satisfied: transformers<5,>=4.11 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (4.29.2)\n",
      "Requirement already satisfied: datasets<3,>=2.4.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml[nlp,streaming]==0.10.1) (2.12.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.136 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from boto3<2,>=1.21.45->mosaicml[nlp,streaming]==0.10.1) (1.29.136)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from boto3<2,>=1.21.45->mosaicml[nlp,streaming]==0.10.1) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from boto3<2,>=1.21.45->mosaicml[nlp,streaming]==0.10.1) (0.6.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (2.0.1)\n",
      "Requirement already satisfied: xxhash in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (2023.5.0)\n",
      "Requirement already satisfied: aiohttp in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (0.14.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (0.18.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from importlib-metadata<5,>=4.11.0->mosaicml[nlp,streaming]==0.10.1) (3.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from packaging<22,>=21.3.0->mosaicml[nlp,streaming]==0.10.1) (3.0.9)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from paramiko<3,>=2.11.0->mosaicml[nlp,streaming]==0.10.1) (4.0.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from paramiko<3,>=2.11.0->mosaicml[nlp,streaming]==0.10.1) (39.0.2)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from paramiko<3,>=2.11.0->mosaicml[nlp,streaming]==0.10.1) (1.5.0)\n",
      "Requirement already satisfied: six in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from paramiko<3,>=2.11.0->mosaicml[nlp,streaming]==0.10.1) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from requests<3,>=2.26.0->mosaicml[nlp,streaming]==0.10.1) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from requests<3,>=2.26.0->mosaicml[nlp,streaming]==0.10.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from requests<3,>=2.26.0->mosaicml[nlp,streaming]==0.10.1) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from requests<3,>=2.26.0->mosaicml[nlp,streaming]==0.10.1) (2023.5.7)\n",
      "Requirement already satisfied: typing-extensions in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from torch<2,>=1.10->mosaicml[nlp,streaming]==0.10.1) (4.5.0)\n",
      "Requirement already satisfied: pytorch-ranger>=0.1.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from torch-optimizer<0.4,>=0.3.0->mosaicml[nlp,streaming]==0.10.1) (0.1.1)\n",
      "Requirement already satisfied: pyDeprecate==0.3.* in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from torchmetrics<0.8,>=0.7.0->mosaicml[nlp,streaming]==0.10.1) (0.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from torchvision>=0.10.0->mosaicml[nlp,streaming]==0.10.1) (9.5.0)\n",
      "Requirement already satisfied: filelock in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from transformers<5,>=4.11->mosaicml[nlp,streaming]==0.10.1) (3.12.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from transformers<5,>=4.11->mosaicml[nlp,streaming]==0.10.1) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from transformers<5,>=4.11->mosaicml[nlp,streaming]==0.10.1) (0.13.3)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from yahp<0.2,>=0.1.3->mosaicml[nlp,streaming]==0.10.1) (0.17.26)\n",
      "Requirement already satisfied: docstring-parser<=0.15,>=0.14.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from yahp<0.2,>=0.1.3->mosaicml[nlp,streaming]==0.10.1) (0.15)\n",
      "Requirement already satisfied: jsonschema<4.8,>=4.7.2 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from yahp<0.2,>=0.1.3->mosaicml[nlp,streaming]==0.10.1) (4.7.2)\n",
      "Requirement already satisfied: Brotli>=1.0.9 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (1.0.9)\n",
      "Requirement already satisfied: matplotlib<4,>=3.5.2 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (3.7.1)\n",
      "Requirement already satisfied: python-snappy<1,>=0.6.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (0.6.1)\n",
      "Requirement already satisfied: torchtext>=0.10 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (0.14.1)\n",
      "Requirement already satisfied: zstd<2,>=1.5.2.5 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (1.5.5.1)\n",
      "Requirement already satisfied: oci<3,>=2.88 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (2.102.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.136->boto3<2,>=1.21.45->mosaicml[nlp,streaming]==0.10.1) (2.8.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from cryptography>=2.5->paramiko<3,>=2.11.0->mosaicml[nlp,streaming]==0.10.1) (1.15.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from aiohttp->datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from aiohttp->datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from aiohttp->datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from aiohttp->datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from aiohttp->datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from aiohttp->datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (1.3.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from jsonschema<4.8,>=4.7.2->yahp<0.2,>=0.1.3->mosaicml[nlp,streaming]==0.10.1) (0.19.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from matplotlib<4,>=3.5.2->mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from matplotlib<4,>=3.5.2->mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from matplotlib<4,>=3.5.2->mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from matplotlib<4,>=3.5.2->mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (1.4.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from matplotlib<4,>=3.5.2->mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (5.12.0)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=17.5.0 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from oci<3,>=2.88->mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (23.1.1)\n",
      "Requirement already satisfied: pytz>=2016.10 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from oci<3,>=2.88->mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (2023.3)\n",
      "Requirement already satisfied: circuitbreaker<2.0.0,>=1.3.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from oci<3,>=2.88->mosaicml-streaming->mosaicml[nlp,streaming]==0.10.1) (1.4.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from ruamel.yaml>=0.17.10->yahp<0.2,>=0.1.3->mosaicml[nlp,streaming]==0.10.1) (0.2.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from pandas->datasets<3,>=2.4.0->mosaicml[nlp,streaming]==0.10.1) (2023.3)\n",
      "Requirement already satisfied: pycparser in /Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko<3,>=2.11.0->mosaicml[nlp,streaming]==0.10.1) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U pip\n",
    "%pip install -U 'mosaicml[nlp, streaming]==0.10.1'\n",
    "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
    "# %pip install 'mosaicml[nlp, tensorboard] @ git+https://github.com/mosaicml/composer.git'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lnshuti/anaconda3/envs/real_estate_data/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 453kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 18.9kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 5.05MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 18.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "# Create a BERT sequence classification model using Hugging Face transformers\n",
    "config = transformers.AutoConfig.from_pretrained('bert-base-uncased')\n",
    "model = transformers.AutoModelForMaskedLM.from_config(config)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer.datasets import StreamingC4\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# Tokenize the C4 dataset\n",
    "train_dataset = StreamingC4(remote='s3://mosaicml-internal-temporary-202210-ocwdemo/mds/1-gz', \n",
    "                                    local='/tmp/c4local',\n",
    "                                    shuffle=True,\n",
    "                                    max_seq_len=128,\n",
    "                                    split='train', \n",
    "                                    tokenizer_name='bert-base-uncased')\n",
    "eval_dataset = StreamingC4(remote='s3://mosaicml-internal-temporary-202210-ocwdemo/mds/1-gz',\n",
    "                                    local='/tmp/c4local',\n",
    "                                    shuffle=True,\n",
    "                                    max_seq_len=128,\n",
    "                                    split='val',\n",
    "                                    tokenizer_name='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "data_collator = transformers.DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True)\n",
    "# data_collator = transformers.DefaultDataCollator(return_tensors='pt')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=False, drop_last=False, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(eval_dataset,batch_size=16, shuffle=False, drop_last=False, collate_fn=data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.collections import MetricCollection\n",
    "from composer.models.huggingface import HuggingFaceModel\n",
    "from composer.metrics import LanguageCrossEntropy, MaskedAccuracy\n",
    "\n",
    "metrics = [LanguageCrossEntropy(vocab_size=tokenizer.vocab_size), MaskedAccuracy(ignore_index=-100)]\n",
    "# Package as a trainer-friendly Composer model\n",
    "composer_model = HuggingFaceModel(model, metrics=metrics, use_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "optimizer = AdamW(\n",
    "    params=composer_model.parameters(),\n",
    "    lr=3e-5, betas=(0.9, 0.98),\n",
    "    eps=1e-6, weight_decay=3e-6\n",
    ")\n",
    "linear_lr_decay = LinearLR(\n",
    "    optimizer, start_factor=1.0,\n",
    "    end_factor=0, total_iters=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from composer import Trainer\n",
    "\n",
    "# Create Trainer Object\n",
    "trainer = Trainer(\n",
    "    model=composer_model, # This is the model from the HuggingFaceModel wrapper class.\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=eval_dataloader,\n",
    "    max_duration=\"1ep\",\n",
    "    optimizers=optimizer,\n",
    "    schedulers=[linear_lr_decay],\n",
    "    device='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    train_subset_num_batches=150,\n",
    "    eval_subset_num_batches=150,\n",
    "    precision='fp32',\n",
    "    seed=17\n",
    ")\n",
    "# Start training\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a BERT sequence classification model using Hugging Face transformers\n",
    "sentiment_model = transformers.AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "sst2_tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# Create BERT tokenizer\n",
    "def tokenize_function(sample):\n",
    "    return sst2_tokenizer(\n",
    "        text=sample['sentence'],\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "# Tokenize SST-2\n",
    "sst2_dataset = datasets.load_dataset(\"glue\", \"sst2\")\n",
    "tokenized_sst2_dataset = sst2_dataset.map(tokenize_function,\n",
    "                                          batched=True, \n",
    "                                          num_proc=cpu_count(),\n",
    "                                          batch_size=100,\n",
    "                                          remove_columns=['idx', 'sentence'])\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "sst2_train_dataset = tokenized_sst2_dataset[\"train\"]\n",
    "sst2_eval_dataset = tokenized_sst2_dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "sst2_data_collator = transformers.data.data_collator.default_data_collator\n",
    "sst2_train_dataloader = DataLoader(sst2_train_dataset, batch_size=16, shuffle=False, drop_last=False, collate_fn=sst2_data_collator)\n",
    "sst2_eval_dataloader = DataLoader(sst2_eval_dataset,batch_size=16, shuffle=False, drop_last=False, collate_fn=sst2_data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "from torchmetrics.collections import MetricCollection\n",
    "from composer.metrics import CrossEntropy\n",
    "from composer.models.huggingface import HuggingFaceModel\n",
    "\n",
    "metrics = [CrossEntropy(), Accuracy()]\n",
    "# Package as a trainer-friendly Composer model\n",
    "composer_sentiment_model = HuggingFaceModel(sentiment_model, metrics=metrics, use_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "sst2_optimizer = AdamW(\n",
    "    params=composer_sentiment_model.parameters(),\n",
    "    lr=3e-5, betas=(0.9, 0.98),\n",
    "    eps=1e-6, weight_decay=3e-6\n",
    ")\n",
    "sst2_linear_lr_decay = LinearLR(\n",
    "    sst2_optimizer, start_factor=1.0,\n",
    "    end_factor=0, total_iters=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from composer import Trainer\n",
    "\n",
    "# Create Trainer Object\n",
    "sentiment_trainer = Trainer(\n",
    "    model=composer_sentiment_model, # This is the model from the HuggingFaceModel wrapper class.\n",
    "    train_dataloader=sst2_train_dataloader,\n",
    "    eval_dataloader=sst2_eval_dataloader,\n",
    "    max_duration=\"1ep\",\n",
    "    optimizers=sst2_optimizer,\n",
    "    schedulers=[sst2_linear_lr_decay],\n",
    "    device='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    train_subset_num_batches=150,\n",
    "    eval_subset_num_batches=150,\n",
    "    precision='fp32',\n",
    "    seed=17\n",
    ")\n",
    "# Start training\n",
    "sentiment_trainer.fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the eval accuracy metric in the final output, we can see our model reaches ~86% accuracy with only 150 iterations of training! Let's visualize a few samples from the validation set to see how our model performs.\n",
    "\n",
    "We can make our own predictions with the model now. Input your own string and see the sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to play around with this and change this string to your own input!\n",
    "INPUT_STRING = \"Hello, my dog is cute\"\n",
    "\n",
    "input_val = tokenizer(INPUT_STRING, return_tensors=\"pt\")\n",
    "\n",
    "input_batch = {k: v.cuda() if torch.cuda.is_available() else v for k, v in input_val.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = composer_sentiment_model(input_batch).logits\n",
    "    \n",
    "prediction = logits.argmax().item()\n",
    "\n",
    "print(f\"Raw prediction: {prediction}\")\n",
    "\n",
    "label = ['negative', 'positive']\n",
    "\n",
    "print(f\"Sentiment: {label[prediction]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Pre-Trained Model\n",
    "Finally, to save the pre-trained model parameters we call the PyTorch save method and pass it the model's state_dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sentiment_trainer.state.model.state_dict(), 'model.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "real_estate_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
